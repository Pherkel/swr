{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# if this does not work, just set device to 'cpu'\n",
    "device = torch.device('mps' if torch.has_mps else 'cpu')\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntroModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This is a sample classe for SWR2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_mapping = torch.nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, input_, *args):\n",
    "        output = self.linear_mapping(input_)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1909,  0.2974], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_model = IntroModel(1, 2).to(device)\n",
    "xx = torch.tensor([1.0], device=device)\n",
    "\n",
    "intro_model.forward(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.tensor([1.0, 2.0, 3.0, 4.0], device=device)\n",
    "\n",
    "#intro_model.forward(xx)  # RuntimeError\n",
    "\n",
    "xx.shape\n",
    "\n",
    "xx = xx.view(4, 1)\n",
    "\n",
    "intro_model.forward(xx)\n",
    "\n",
    "# now it works and gives the four results in parrallel\n",
    "\n",
    "yy = intro_model.forward(xx)\n",
    "\n",
    "# The first dimension is interpreted as batch dimension and all computatoins\n",
    "# are done in parralel along the first dimension.\n",
    "\n",
    "yy.shape  # [4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9958],\n",
       "        [-0.6654]], requires_grad=True)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The linear_mapping maps one number on two numbers. This is done by a linear\n",
    "# mapping with four paramerters. The four parameters are two weights and two\n",
    "# biases.\n",
    "\n",
    "intro_model.linear_mapping.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1951,  0.9628], requires_grad=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_model.linear_mapping.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The linear mapping multiplies the weights and adds the bias.\n",
    "xx = torch.tensor([3.1415], device=device)\n",
    "\n",
    "yy0 = intro_model.linear_mapping.weight[0] * xx + intro_model.linear_mapping.bias[0]\n",
    "yy1 = intro_model.linear_mapping.weight[1] * xx + intro_model.linear_mapping.bias[1]\n",
    "\n",
    "yy = intro_model.forward(xx)\n",
    "\n",
    "yy == torch.cat((yy0, yy1))  # they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to change the behavior of the intro_model, so that it produces\n",
    "# two times the input as the first number and the negative input + 3 as the\n",
    "# second number.\n",
    "\n",
    "yy_true = torch.tensor([2 * xx, -xx + 3], device=device)\n",
    "\n",
    "# now we let the intro_model predict the (wrong) numbers\n",
    "yy = intro_model.forward(xx)\n",
    "\n",
    "# calculate an error\n",
    "error = torch.mean((yy_true - yy) ** 2)\n",
    "\n",
    "# backpropagete the error to get gradients on all weights and biases\n",
    "error.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-30.1789],\n",
       "        [ -3.0978]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_model.linear_mapping.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.6065, -0.9861])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_model.linear_mapping.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gradients give us the information how we have to change the weights and\n",
    "# biases to minimize the resulting error. We will change the weights and biases\n",
    "# only a little bit. This is called the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "new_weights = intro_model.linear_mapping.weight - learning_rate * intro_model.linear_mapping.weight.grad\n",
    "new_biases = intro_model.linear_mapping.bias - learning_rate * intro_model.linear_mapping.bias.grad\n",
    "\n",
    "intro_model.linear_mapping.weight = torch.nn.Parameter(new_weights)\n",
    "intro_model.linear_mapping.bias = torch.nn.Parameter(new_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in epoch 0 is: 37.04347610473633\n",
      "Error in epoch 1 is: 29.428565979003906\n",
      "Error in epoch 2 is: 23.3790283203125\n",
      "Error in epoch 3 is: 18.573074340820312\n",
      "Error in epoch 4 is: 14.755064010620117\n",
      "Error in epoch 5 is: 11.72191333770752\n",
      "Error in epoch 6 is: 9.312274932861328\n",
      "Error in epoch 7 is: 7.397978782653809\n",
      "Error in epoch 8 is: 5.877198696136475\n",
      "Error in epoch 9 is: 4.669041633605957\n",
      "Error in epoch 10 is: 3.7092416286468506\n",
      "Error in epoch 11 is: 2.946743965148926\n",
      "Error in epoch 12 is: 2.3409907817840576\n",
      "Error in epoch 13 is: 1.8597605228424072\n",
      "Error in epoch 14 is: 1.4774566888809204\n",
      "Error in epoch 15 is: 1.173740029335022\n",
      "Error in epoch 16 is: 0.9324582815170288\n",
      "Error in epoch 17 is: 0.7407752275466919\n",
      "Error in epoch 18 is: 0.5884963274002075\n",
      "Error in epoch 19 is: 0.4675213396549225\n",
      "Error in epoch 20 is: 0.37141457200050354\n",
      "Error in epoch 21 is: 0.2950640320777893\n",
      "Error in epoch 22 is: 0.23440854251384735\n",
      "Error in epoch 23 is: 0.18622197210788727\n",
      "Error in epoch 24 is: 0.1479407548904419\n",
      "Error in epoch 25 is: 0.11752899736166\n",
      "Error in epoch 26 is: 0.09336892515420914\n",
      "Error in epoch 27 is: 0.0741754025220871\n",
      "Error in epoch 28 is: 0.0589272640645504\n",
      "Error in epoch 29 is: 0.04681386053562164\n"
     ]
    }
   ],
   "source": [
    "# Now lets do this 10 times in a loop and see if the error gets smaller:\n",
    "\n",
    "for epoch in range(30):\n",
    "    yy = intro_model.forward(xx)\n",
    "    error = torch.mean((yy_true - yy) ** 2)\n",
    "    error.backward()\n",
    "    new_weights = intro_model.linear_mapping.weight - learning_rate * intro_model.linear_mapping.weight.grad\n",
    "    new_biases = intro_model.linear_mapping.bias - learning_rate * intro_model.linear_mapping.bias.grad\n",
    "\n",
    "    intro_model.linear_mapping.weight = torch.nn.Parameter(new_weights)\n",
    "    intro_model.linear_mapping.bias = torch.nn.Parameter(new_biases)\n",
    "\n",
    "    print(f\"Error in epoch {epoch} is: {float(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.5558255314826965\n"
     ]
    }
   ],
   "source": [
    "# The model can now create the desired output for this single input xx =\n",
    "# 3.1415, but what happens if we give it a new input?\n",
    "\n",
    "xx = torch.tensor([1.5])\n",
    "yy_true = torch.tensor([2 * xx, -xx + 3])\n",
    "yy = intro_model.forward(xx)\n",
    "error = torch.mean((yy_true - yy) ** 2)\n",
    "\n",
    "print(f\"Error: {float(error)}\")\n",
    "# For this new number we have a huge error :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in epoch 0 is: 0.5558255314826965\n",
      "Error in epoch 1 is: 0.5202839374542236\n",
      "Error in epoch 2 is: 0.48701515793800354\n",
      "Error in epoch 3 is: 0.4558735489845276\n",
      "Error in epoch 4 is: 0.42672333121299744\n",
      "Error in epoch 5 is: 0.3994370698928833\n",
      "Error in epoch 6 is: 0.3738956153392792\n",
      "Error in epoch 7 is: 0.349987268447876\n",
      "Error in epoch 8 is: 0.32760781049728394\n",
      "Error in epoch 9 is: 0.3066592812538147\n",
      "Error in epoch 10 is: 0.28705033659935\n",
      "Error in epoch 11 is: 0.26869526505470276\n",
      "Error in epoch 12 is: 0.25151386857032776\n",
      "Error in epoch 13 is: 0.23543114960193634\n",
      "Error in epoch 14 is: 0.22037681937217712\n",
      "Error in epoch 15 is: 0.20628505945205688\n",
      "Error in epoch 16 is: 0.193094402551651\n",
      "Error in epoch 17 is: 0.18074722588062286\n",
      "Error in epoch 18 is: 0.16918955743312836\n",
      "Error in epoch 19 is: 0.1583709567785263\n",
      "Error in epoch 20 is: 0.14824417233467102\n",
      "Error in epoch 21 is: 0.1387648731470108\n",
      "Error in epoch 22 is: 0.12989172339439392\n",
      "Error in epoch 23 is: 0.12158595770597458\n",
      "Error in epoch 24 is: 0.11381127685308456\n",
      "Error in epoch 25 is: 0.10653373599052429\n",
      "Error in epoch 26 is: 0.09972155839204788\n",
      "Error in epoch 27 is: 0.093345046043396\n",
      "Error in epoch 28 is: 0.087376169860363\n",
      "Error in epoch 29 is: 0.081789031624794\n"
     ]
    }
   ],
   "source": [
    "# But can we minimize the error for this values as well?\n",
    "\n",
    "for epoch in range(30):\n",
    "    yy = intro_model.forward(xx)\n",
    "    error = torch.mean((yy_true - yy) ** 2)\n",
    "    error.backward()\n",
    "    new_weights = intro_model.linear_mapping.weight - learning_rate * intro_model.linear_mapping.weight.grad\n",
    "    new_biases = intro_model.linear_mapping.bias - learning_rate * intro_model.linear_mapping.bias.grad\n",
    "\n",
    "    intro_model.linear_mapping.weight = torch.nn.Parameter(new_weights)\n",
    "    intro_model.linear_mapping.bias = torch.nn.Parameter(new_biases)\n",
    "\n",
    "    print(f\"Error in epoch {epoch} is: {float(error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in epoch 0 is: 0.9782249208830762\n",
      "Average Error in epoch 1 is: 0.11989089231647085\n",
      "Average Error in epoch 2 is: 0.014665360006765694\n",
      "Average Error in epoch 3 is: 0.0017985189180308226\n",
      "Average Error in epoch 4 is: 0.0002200765327825138\n",
      "Average Error in epoch 5 is: 2.6860218667934532e-05\n",
      "Average Error in epoch 6 is: 3.289766183272036e-06\n",
      "Average Error in epoch 7 is: 4.0378691707587677e-07\n",
      "Average Error in epoch 8 is: 4.9406868107837457e-08\n",
      "Average Error in epoch 9 is: 6.056442563018294e-09\n",
      "Average Error in epoch 10 is: 7.324438680567091e-10\n",
      "Average Error in epoch 11 is: 9.109616762315032e-11\n",
      "Average Error in epoch 12 is: 3.490397207372986e-11\n",
      "Average Error in epoch 13 is: 3.0160756531172337e-11\n",
      "Average Error in epoch 14 is: 2.963679114620366e-11\n",
      "Average Error in epoch 15 is: 2.956294389844238e-11\n",
      "Average Error in epoch 16 is: 2.938204200775285e-11\n",
      "Average Error in epoch 17 is: 2.9478133059535064e-11\n",
      "Average Error in epoch 18 is: 2.954460509574375e-11\n",
      "Average Error in epoch 19 is: 2.959376334266128e-11\n",
      "Average Error in epoch 20 is: 2.950646123267564e-11\n",
      "Average Error in epoch 21 is: 2.982965340014854e-11\n",
      "Average Error in epoch 22 is: 2.9512176105694896e-11\n",
      "Average Error in epoch 23 is: 2.93303260151534e-11\n",
      "Average Error in epoch 24 is: 2.9429514381007493e-11\n",
      "Average Error in epoch 25 is: 2.945234743589875e-11\n",
      "Average Error in epoch 26 is: 2.954078398564874e-11\n",
      "Average Error in epoch 27 is: 2.951131318484901e-11\n",
      "Average Error in epoch 28 is: 2.962703742059869e-11\n",
      "Average Error in epoch 29 is: 2.9403868020971833e-11\n",
      "Parameter containing:\n",
      "tensor([[ 2.0000],\n",
      "        [-1.0000]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.2711e-08,  3.0000e+00], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# The problem is that this might increase the error for the first number again.\n",
    "# Solution: Let us do it for many numbers over and over again.\n",
    "\n",
    "import numpy as np\n",
    "xxs = np.array(np.random.normal(size=100), dtype=np.float32)\n",
    "\n",
    "for epoch in range(30):\n",
    "    np.random.shuffle(xxs)  # we don't want to have the same order in each epoch\n",
    "    errors = list()\n",
    "    for xx in xxs:\n",
    "        xx = torch.tensor([xx], device=device)\n",
    "        yy_true = torch.tensor([2 * xx, -xx + 3], device=device)\n",
    "        yy = intro_model.forward(xx)\n",
    "        error = torch.mean((yy_true - yy) ** 2)\n",
    "        error.backward()\n",
    "        new_weights = intro_model.linear_mapping.weight - learning_rate * intro_model.linear_mapping.weight.grad\n",
    "        new_biases = intro_model.linear_mapping.bias - learning_rate * intro_model.linear_mapping.bias.grad\n",
    "\n",
    "        intro_model.linear_mapping.weight = torch.nn.Parameter(new_weights)\n",
    "        intro_model.linear_mapping.bias = torch.nn.Parameter(new_biases)\n",
    "        errors.append(float(error))\n",
    "    print(f\"Average Error in epoch {epoch} is: {np.mean(errors)}\")\n",
    "    \n",
    "print(intro_model.linear_mapping.weight)\n",
    "print(intro_model.linear_mapping.bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you find a -1, 0, 2, and 3 in the weights and biases? Where are these four numbers present as well?\n",
    "\n",
    "Yes, you can find these numbers. 2 and -1 correspond to the weights that are multiplied with the first and second input variable respectively\n",
    "0 and 3 are the biases that are added to the first and second variable\n",
    "this corresponds to the formula that we wanted to learn from the beginngin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a sencond intro_model that takes a vector with two numbers as\n",
    "# input and outputs a single number. Train the second intro model to produce\n",
    "# the sum of the two numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: 1.7182968854904175\n"
     ]
    }
   ],
   "source": [
    "xx = torch.tensor([1.0, 2.0], device=device)\n",
    "\n",
    "yy_true = torch.tensor([3.0], device=device)\n",
    "\n",
    "intro_model2 = IntroModel(2, 1).to(device)\n",
    "\n",
    "yy = intro_model2(xx)\n",
    "\n",
    "error = torch.mean((yy_true - yy) ** 2)\n",
    "\n",
    "print(f\"Initial error: {float(error)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I tried to optimize this code to run faster :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in epoch 0 is: 1.410851275920868\n",
      "Average Error in epoch 1 is: 0.9383809208869934\n",
      "Average Error in epoch 2 is: 0.6241150557994842\n",
      "Average Error in epoch 3 is: 0.4150745332241058\n",
      "Average Error in epoch 4 is: 0.2760907977819443\n",
      "Average Error in epoch 5 is: 0.18362259715795518\n",
      "Average Error in epoch 6 is: 0.12213777154684066\n",
      "Average Error in epoch 7 is: 0.08124077990651131\n",
      "Average Error in epoch 8 is: 0.05403101779520512\n",
      "Average Error in epoch 9 is: 0.03594069890677929\n",
      "Average Error in epoch 10 is: 0.02390327546745539\n",
      "Average Error in epoch 11 is: 0.0159001374617219\n",
      "Average Error in epoch 12 is: 0.010575468372553586\n",
      "Average Error in epoch 13 is: 0.007034363644197583\n",
      "Average Error in epoch 14 is: 0.004678836092352867\n",
      "Average Error in epoch 15 is: 0.0031122481916099785\n",
      "Average Error in epoch 16 is: 0.0020701530389487743\n",
      "Average Error in epoch 17 is: 0.0013769677374511958\n",
      "Average Error in epoch 18 is: 0.0009159039240330457\n",
      "Average Error in epoch 19 is: 0.0006092309020459652\n",
      "Average Error in epoch 20 is: 0.0004052513395436108\n",
      "Average Error in epoch 21 is: 0.00026955878420267256\n",
      "Average Error in epoch 22 is: 0.00017931203183252364\n",
      "Average Error in epoch 23 is: 0.00011927579762414098\n",
      "Average Error in epoch 24 is: 7.934289751574398e-05\n",
      "Average Error in epoch 25 is: 5.277777854644228e-05\n",
      "Average Error in epoch 26 is: 3.510853930492886e-05\n",
      "Average Error in epoch 27 is: 2.3354038421530277e-05\n",
      "Average Error in epoch 28 is: 1.553530546516413e-05\n",
      "Average Error in epoch 29 is: 1.0334516900911694e-05\n",
      "Average Error in epoch 30 is: 6.874759537822683e-06\n",
      "Average Error in epoch 31 is: 4.572928150992084e-06\n",
      "Average Error in epoch 32 is: 3.0420394523389405e-06\n",
      "Average Error in epoch 33 is: 2.023684010055149e-06\n",
      "Average Error in epoch 34 is: 1.3462362858263077e-06\n",
      "Average Error in epoch 35 is: 8.957427610312152e-07\n",
      "Average Error in epoch 36 is: 5.958867518529587e-07\n",
      "Average Error in epoch 37 is: 3.9642121123506514e-07\n",
      "Average Error in epoch 38 is: 2.6368515477770415e-07\n",
      "Average Error in epoch 39 is: 1.7540484975597792e-07\n",
      "Average Error in epoch 40 is: 1.1667101063039809e-07\n",
      "Average Error in epoch 41 is: 7.761151508134389e-08\n",
      "Average Error in epoch 42 is: 5.1632009956392724e-08\n",
      "Average Error in epoch 43 is: 3.434971187488145e-08\n",
      "Average Error in epoch 44 is: 2.2849343928044163e-08\n",
      "Average Error in epoch 45 is: 1.5202237424460918e-08\n",
      "Average Error in epoch 46 is: 1.0103774172876001e-08\n",
      "Average Error in epoch 47 is: 6.718102563141315e-09\n",
      "Average Error in epoch 48 is: 4.461887792572838e-09\n",
      "Average Error in epoch 49 is: 2.9672028389882143e-09\n",
      "Parameter containing:\n",
      "tensor([[1.0000, 1.0000]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.6604e-05], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# assuming that we have to train the model for a few epochs to learn the new formula\n",
    "xxs = np.array(np.random.normal(size=(10000, 2)), dtype=np.float32)\n",
    "xxs_tensor = torch.from_numpy(xxs).to(device)\n",
    "batch_size = 1000\n",
    "num_batches = len(xxs_tensor) // batch_size\n",
    "for epoch in range(50):\n",
    "    xxs_tensor = xxs_tensor[torch.randperm(len(xxs_tensor))]  # we don't want to have the same order in each epoch\n",
    "    errors = list()\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i + 1) * batch_size\n",
    "        xx_batch = xxs_tensor[batch_start:batch_end]\n",
    "        yy_true_batch = xx_batch.sum(dim=1, keepdim=True)\n",
    "        yy_batch = intro_model2.forward(xx_batch)\n",
    "        error_batch = torch.mean((yy_true_batch - yy_batch) ** 2)\n",
    "        error_batch.backward()\n",
    "        learning_rate = 0.01\n",
    "        new_weights = intro_model2.linear_mapping.weight - learning_rate * intro_model2.linear_mapping.weight.grad\n",
    "        new_biases = intro_model2.linear_mapping.bias - learning_rate * intro_model2.linear_mapping.bias.grad\n",
    "\n",
    "        intro_model2.linear_mapping.weight = torch.nn.Parameter(new_weights)\n",
    "        intro_model2.linear_mapping.bias = torch.nn.Parameter(new_biases)\n",
    "        errors.append(float(error_batch))\n",
    "    print(f\"Average Error in epoch {epoch} is: {np.mean(errors)}\")\n",
    "    \n",
    "print(intro_model2.linear_mapping.weight)\n",
    "print(intro_model2.linear_mapping.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swr-4J-wxfLf-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
